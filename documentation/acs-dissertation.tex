%% 
%% ACS project dissertation template. 
%% 
%% Currently designed for printing two-sided, but if you prefer to 
%% print single-sided just remove ",twoside,openright" from the 
%% \documentclass[] line below. 
%%
%%
%%   SMH, May 2010. 

\documentclass[a4paper,12pt,twoside,openright]{report}
\usepackage{graphicx}

%%
%% EDIT THE BELOW TO CUSTOMIZE
%%

\def\authorname{Martin Marinov\xspace}
\def\authorcollege{St Edmund's College\xspace}
\def\authoremail{mtm46@cam.ac.uk}
\def\dissertationtitle{Remote video eavesdropping using a software-defined radio platform}
\def\wordcount{??,???}


\usepackage{epsfig,graphicx,parskip,setspace,tabularx,xspace,epstopdf,amssymb,caption,subcaption,hyperref} 
\graphicspath{ {./images/} }

%% START OF DOCUMENT
\begin{document}


%% FRONTMATTER (TITLE PAGE, DECLARATION, ABSTRACT, ETC) 
\pagestyle{empty}
\singlespacing
\input{titlepage}
\onehalfspacing
\input{declaration}
\singlespacing
\input{abstract}

\pagenumbering{roman}
\setcounter{page}{0}
\pagestyle{plain}
\tableofcontents
%% \listoffigures
%% \listoftables

\onehalfspacing

%% START OF MAIN TEXT 

\chapter{Introduction}
\pagenumbering{arabic} 
\setcounter{page}{1} 

Interference is usually regarded as a simple annoyance. It is not difficult to experience TV signal or radio station getting distorted because of a device operating in the vicinity of your receiver. Manufacturers have to meet certain requirements so that their products do not cause interference with other systems. The truth is that the emanation is linked to the way the emitting device works internally. The interference is generated by alternating currents due to switches, oscillators and other electronic and mechanical components operating inside the device. Therefore it carries some information about the internal state of the device.

This means that a simple annoyance could potentially turn into a security leak, broadcasting sensitive data into the wild. A clever attacker could possibly distinguish different modes of operation or even recover raw data that is being processed. And the industry standards that manufacturers follow to minimise interference say nothing about the information such interference may carry. Furthermore, a very sensitive detector can pick up such signals at levels several magnitudes lower than what industry standards specify as radiation limits.

In the case of video displays the issue is particularly important. Having a secure, encrypted computer system that unintentionally broadcasts its display in clear text does not sound secure at all. The attacker could be fully passive and the breach could be never detected. Furthermore, the repeating nature of the signal combined with the long video wires that could act as antennas means that such signals can travel very long distances, allowing practical attacks from vans across the street \cite{van1985electromagnetic}.

However very little research has been published into the open literature on the topic. The main reason is possibly the expensive specialised equipment required to conduct experiments with compromising emanations. One of the goals of this project is to address this issue and demonstrate that a practical attack could be undertaken using an affordable software-defined radio receiver.

\section{History}

A compass needle points north when put next to a wire that has current flowing in it. However, turning off the current makes the needle twitch i.e. temporary deflecting from the north direction. The same effect could be seen if the current is turned back on. This phenomenon was noticed by the Danish physicist Hans Christian \O rsted in April 1820 \cite{jelved1998selected}. It shows that a changing electric current creates a magnetic field and vice versa. Later this phenomenon was utilised to create the electrical telegraph and allow for long distance communications.

However, the undesired effects of this phenomenon remained unnoticed for a couple of decades. British army noticed crosstalk between telephone wires during the Nile and Suakin expedition in 1884-85 \cite{nalder1958history}. However, the first reported exploitation of the phenomenon was in 1914 when earth leakage from telephone wires caused a lot of crosstalk. Listening posts were established in order to intercept enemy messages. Later next year valve amplifiers were utilised which allowed for extended listening range \cite{anderson2008security}.

The US National Security Agency conducted a classified research with codename TEMPEST in 1972 \cite{friedman2007tempest}. The document was later declassified in 2007. It describes unwanted emanations coming from a Bell-telephone mixing device that was used for cryptographic encryption. The signal allowed for an attacker to reconstruct the original text. Researchers at Bell Lab demonstrated a practical attack from about 80 feet away that allowed reconstructing about 75\% of the plain text being processed by the machine.

Computer monitors started to become common in the end of the 20th century. Wim van Eck published the first unclassified technical analysis of the security risks of emanations from computer monitors in 1985 \cite{van1985electromagnetic}. The next important publication regarding video emanations came from Markus Kuhn nearly 20 years later in 2003 \cite{kuhn2003compromising}. 

\section{Related Work}
\label{sec:RelatedWork}

With the notable exception of van Eck and Kuhn, there is no research on the topic in the open literature. This is worrying since the phenomenon is real and could easily be exploited by an adversary.

\subsection{Work of Wim van Eck}

\textit{Electromagnetic Radiation from Video Display Units: An Eavesdropping Risk?} \cite{van1985electromagnetic} was the first publicised research on the risks of compromising emanations. Wim van Eck describes the similarities between contemporary video monitors and black and white TV sets. He explains that these could be exploited to build a cheap eavesdropping device.

The document describes usage of a modified black and white commercial television receiver to conduct a very successful practical attack. Furthermore, a demonstration is done outside the laboratory in real world conditions. Van Eck proves that the attack is a viable security thread. He continues discussing possible sources of the emissions and ways of defending against such a attacks.

However, there are some problems with his implementation:

\begin{itemize}

  \item The modification of the TV receiver, although inexpensive, requires advanced specialised knowledge to pull of.
  \item The fact that the device needs constant manual adjustments to keep the oscillators in the receiver and transmitter in sync makes it difficult to use in practice.
  \item Technology has changed dramatically since the publishing of the paper. The attack will no longer work on modern monitors due to the variety of video modes available which now differ significantly from broadcast television. 
  \item No room for further automated signal processing.

\end{itemize}

Very likely due to these reasons, there was no open research on the topic for years to come.
 
\subsection{Work of Markus Kuhn}

Markus Kuhn was able to improve on the results achieved by van Eck with his \textit{Compromising emanations: eavesdropping risks of computer displays} \cite{kuhn2003compromising}. In the technical report, Kuhn analyses in a very mathematically detailed manner the properties of the waves emitted and their source. He describes the possible equipment an attacker may need to intercept and process the signal. He conducts experiments and constructs a system for real time monitoring using an FPGA board, a specialised wideband AM radio receiver and a off-the shelf VGA video monitor. 

However there are a few caveats:

\begin{itemize}

  \item A researcher will need access to very expensive equipment in order to repeat his experiments.
  \item As with van Ecks' system, Kuhn's solution still requires manual synchronisation.
  \item Digital signal processing for improving reception of weak signals (like time averaging) was not attempted.
  \item An attacker will need to know the exact video mode the target is using.

\end{itemize}

The report also mentions possible ways of modulating hidden messages into the signal. Kuhn also discusses ways of defending against such attacks using hardware and software solutions. He demonstrate automatic character recognitions. The report also includes experiments with optical eavesdropping of CRT displays.

Overall his system improves on van Eck's one by supporting a variety of modern video modes. Thus Kuhn was able to prove that the threads outlined almost two centuries ago are still valid. In a later paper \cite{kuhn2005electromagnetic} he focuses on digital displays and explains that the same attack vector could also be used in that context.

The current work is inspired by Dr Kuhn's solution. His report simplifies further research into the topic by giving a very detailed and mathematical description of the emanated signal and its properties. This gave room for a number of improvements that were eventually implemented.

\section{Achieved Goals}

The project aims to raise awareness of the potential security implications of the compromising emanations emitted by video monitors. It implements the principles outlined in the related work section \ref{sec:RelatedWork} using a completely new approach: utilising a software-defined radio receiver. It also combines them into a single portable software library. In its basic form it allows tuning to a video signal by manually controlling the vertical and horizontal synchronisation similar to the implementation that van Eck and Kuhn have used in their practical demonstrations.

The system builds on top of the existing research by having achieved the following additional goals that were never done before:

\begin{itemize}

  \item Uses affordable unmodified off-the-shelf equipment.
  \item Almost no specialised experience is necessary to operate the system.
  \item No prior knowledge of the target machine video parameters is required. The system can automatically estimate them remotely in real time.
  \item Reception of weaker signals is possible due to additional digital signal processing.
  \item Eliminates the need for constant manual adjustments in order to keep the picture steady on the screen.
  \item Open source license simplifying further research on the topic.

\end{itemize}

The source code and the latest pre-compiled binaries could be obtained from \href{https://github.com/martinmarinov/TempestSDR}{github.com/martinmarinov/TempestSDR}. If user's computer is running OS X, Windows or Linux, a multiplatform statically precompiled Java jar file is available for starting up the system in a couple of clicks.
\footnote{Some device drivers might not be available on all operating systems. At time of writing the OS X binaries need to be compiled manually. Refer to the README for more information.}

The system supports a plug-in architecture that allows simplified development of device drivers for any software-defined radio frontend. Currently supported plug-ins:

\begin{itemize}

  \item Pre-recorded file with raw IQ samples (Multiplatform support)
  \item Mirics SDR (Windows support)
  \item UHD (Linux and OS X support)
  \item ExtIO (Windows support)

\end{itemize}

The library comes with a Java GUI but it could be used independently by any other system as a shared or statically linked library. Furthermore the core library is written in C and has no additional dependencies making it portable and easy to compile.

There are a few caveats about the proposed system:
\begin{itemize}

  \item The project does not discuss ways of limiting the amount of information leaked via such compromising emanations. This is beyond the scope of the project. The system, however, could be used for further research on the topic. It could possibly aid such attempts by serving as a rapid prototyping tool.
  \item The performance of the system depends on the speed of the CPU of the attacker. No GPU acceleration was implemented since it wasn't really necessary. 35 fps could easily be achieved on a Intel Core i5 laptop without GPU acceleration.
  \item Difficult to compare its core performance to existing implementations due to the fundamental differences of the underlying architectures.
  \item More research could be dong to improve the user friendliness of the GUI.
  
\end{itemize}

\chapter{Background}

\section{Electronic Emanations} 

\section{IQ sampling} 

\chapter{Methodology} 

\section{Analogue Video Signals}

Almost all contemporary video monitors are raster based. The image is transferred from the video controller to the display in scanlines that occur at a specific rate. Each of these scanlines contains a number of pixels which are continuously encoded as a time varying signal. This signal is generated internally in the video controller by an oscillator which runs at the pixel clock rate. The signal is thereafter multiplied by the pixel intensities at the specific time.

Let's assume that the signal started transmitting at time $t=0$, and each video frame contains $h$ scanlines, each of which contains $w$ pixels. The frequency with which frames are being generated is $f_{f}$ frames per second. Therefore the duration of transmission of each individual pixel is \begin{equation}
\label{eq:tdelta_definition}
T_{\Delta}=\frac{1}{w h f_{f}}
\end{equation}
Furthermore at time $t$ frame number $n_{t}$ started transmission where 
\begin{equation}
n_{t}=\lfloor t f_{f} \rfloor
\end{equation}
Therefore 
if we assume that the top left corner of a frame has coordinates $(0, 0)$, a pixel at position $(x, y)$ in frame $n_{t}$ will start to be transmitted at time
\begin{equation}
T_{(x,y)}= (y w + x + n_{t} w h) T_{\Delta}
\end{equation}
and will finish transmission before time 
\begin{equation}
T_{(x+1,y)} = T_{(x,y)} + T_{\Delta} =(y w + x + 1 + n_{t} w h) T_{\Delta}
\end{equation}
at which the next pixel will start transmitting.

In practice $w$ and $h$ are determined by the screen resolution and $f_{f}$ is simply the screen refresh rate. For a typical screen resolution of $width \times height$, it is true that $w \geq width$ and $h \geq height$. The reason is that video signals tend to have additional blanking intervals. This means more pixels are transmitted than what is in the active video region. This gives opportunity for the receiving monitor to synchronise its internal clock, calibrate its colour levels or in case of CRT, allow enough time for the electron beam to return to the beginning of the next line on the screen. The synchronisation timings for personal computers have been standardised by Video Electronics Standards Association (VESA) \cite{vesa}.

In order to decode an individual pixel, the receiving monitor has its own internal oscillator. It locks it to the pixel rate of the incoming signal either via an external clock source or using the blanking intervals. Once it receives the signal for an individual pixel, its amplitude (or binary content in case of digital signal) will correspond to the intensity. This allows the monitor to display the video in real time. If multiple colours are desired, they can be transmitted separately on different wires in the same fashion.

\section{Generated Radio Wave}

\subsection{Signal Equation}
Let's assume the discrete pixels in a video signal have intensities $v_{i} (i \in \mathbb{Z})$ and are being transmitted for a duration of $T_{\Delta}=\frac{1}{w h f_{f}}$ (from \ref{eq:tdelta_definition}). Let's also assume that the shape of the pixel is $p(t)$ where $p(t)=0$ for $|t| > \frac{T_{\Delta}}{2}$. We know that pixel $i$ starts transmitting at time $t_{i}=i T_{\Delta}$ (if we assume that that pixel 0 was transmitted at $t=0$). Also the amplitude of the signal of the transmitted pixel is linearly dependant on its intensity $v_{i}$. Then the resulting signal between time $t_{i}$ and $t_{i+1}$ will have the form $v_{i} p(t-i T_{\Delta})$. To generalise for all $i$, the resulting actual transmitted radio wave in the time domain will have the form 
\begin{equation}
\label{eq:video_signal}
\tilde{v}(t) = \sum\limits_{i=-\infty}^{\infty} v_{i} p(t-i T_{\Delta})
\end{equation}
Which is a continuous function. Equation \ref{eq:video_signal} can be rewritten as a convolution with a Dirac delta function
\begin{equation}
\label{eq:vasconv}
\tilde{v}(t) = p(t) \ast \left( \sum\limits_{i=-\infty}^{\infty} v_{i} \cdot \delta(t-i T_{\Delta}) \right) = p(t) \ast \hat{v}(t)
\end{equation}
Where we have put
\begin{equation}
\label{eq:vhattdef}
\hat{v}(t) = \sum\limits_{i=-\infty}^{\infty} v_{i} \cdot \delta(t-i T_{\Delta})
\end{equation}
Note that this results in infinitesimally short (in time) spikes at values exact integer multiples of $T_{\Delta}$ with amplitudes weighted to the pixel intensities at that time. We can view \ref{eq:vasconv} as the pixel shape being repeated at intervals of $T_{\Delta}$ modulated by $v_{i}$. 

\subsection{Sampling}
We can notice that \ref{eq:vhattdef} looks like the result of a continuous signal being sampled at discrete points in time $T_{\Delta}$ apart. If we call this continuous signal $v(t)$, then we can rewrite the equation so that it reads
\begin{equation}
\hat{v}(t) = \sum\limits_{i=-\infty}^{\infty} v(t) \cdot \delta(t-i T_{\Delta}) = v(t) \sum\limits_{i=-\infty}^{\infty} \delta(t-i T_{\Delta})
\end{equation}
The requirement is that if $v(t)$ is sampled at discrete intervals $i T_{\Delta}$, it should be equal to the corresponding pixel values i.e. $v(0)=v_{0}$, $v(T_{\Delta})=v_{1}$, $v(2 T_{\Delta})=v_{2}$, etc. This would mean that we can precisely obtain the samples from the continuous function by applying the series of Dirac delta functions. However, now we would also like to be able to obtain the continuous signal by only having the sampled values $v_{i}$. This means that we need a unique perfect reconstruction i.e. to be able to obtain all $v_{i}$ from $v(x)$ and $v(x)$ from all $v_{i}$. This condition is satisfied by the Whittaker--Shannon interpolation formula which can give us the condition for perfect reconstruction for digitally sampled signals. It states that the continuous signal could be uniquely reconstructed using $sinc$ interpolation. If we apply it to our $v_{i}$ samples, it yields
\begin{equation}
v(t) = \sum\limits_{k=-\infty}^{\infty} v_{k} \cdot sinc ( \pi \left( \frac{t}{T_{\Delta}} - k \right) )
\end{equation}
We can verify that when $t=i T_{\Delta}$, then $sinc(\pi (i-k) )$ will always yield $0$ except for when $i = k$ in which case it will be $1$. Therefore we have proved that $v(i T_{\Delta}) = v_{i}$.

\subsection{Repetitions}
Now let's revise some mathematical identities. According to the convolution theorem
\begin{equation}
\mathcal{F} \left\{ g \cdot h \right\} = \mathcal{F} \left\{ g \right\} \ast  \mathcal{F} \left\{ h \right\}
\end{equation}
Which reads: the Fourier transform of a multiplication of two functions is equivalent to the Fourier transforms of the individual functions convolved together. And vice versa
\begin{equation}
\mathcal{F} \left\{ g \ast h \right\} = \mathcal{F} \left\{ g \right\} \cdot  \mathcal{F} \left\{ h \right\}
\end{equation}
The convolution of the Fourier transform of two functions is equivalent to the individual Fourier transforms of the two functions multiplied together.
Also
\begin{equation}
\mathcal{F} \left\{ \sum\limits_{n=-\infty}^{\infty}  \delta(t-n k) \right\} = \frac{1}{k} \sum\limits_{n=-\infty}^{\infty}  \delta \left( t-\frac{n}{k} \right)
\end{equation}
Using the last three identities, we can write the Fourier transform of \ref{eq:vasconv} as
\begin{equation} 
\mathcal{F} \left\{ p(t) \ast \hat{v}(t) \right\} = \tilde{V}(f) =
\left[ \frac{1}{T_{\Delta}} \cdot P(f) \cdot V(f) \right] \ast
\left[ \sum\limits_{i=-\infty}^{\infty}  \delta \left( t-\frac{i}{T_{\Delta}} \right) \right]
\end{equation}
Where $P(f)$ is the Fourier transform of $p(t)$, $\tilde{V}(f)$ is the Fourier transform of $\tilde{v}(t)$ and $V(f)$ is the Fourier transform of $v(t)$. If we put 
\begin{equation} 
\label{eq:gfdef}
G(f) = \frac{1}{T_{\Delta}} \cdot P(f) \cdot V(f)
\end{equation}
Then we we can arrive to our final conclusion that
\begin{equation}
\label{eq:vspectrum}
\tilde{V}(f) = G(f) \ast
\left[ \sum\limits_{i=-\infty}^{\infty}  \delta \left( t-\frac{i}{T_{\Delta}} \right) \right]
\end{equation}
This simply means that the signal spectrum $G(f)$ repeats at regular intervals throughout the radio spectrum with a frequency of $\frac{1}{T_{\Delta}} = w h f_(f)$.

For example, for a resolution of $800 \cdot 600 @ 60fps$ (ignore blanking intervals for simplicity), we would have a frequency of $\frac{1}{T_{\Delta}} = 800 \cdot 600 \cdot 60 = 28.8 MHz$. This means that we would expect to find such a signal centred at DC, 28.8 MHz, 57.6 MHz, 86.4 MHz, etc.

\subsection{Sampling Rate}

In order to obtain the full video signal, we need to know what is the minimum rate at which we need to sample the baseband. We saw from \ref{eq:vspectrum} that $G(f)$ repeats at the regular intervals. In fact we can see from \ref{eq:gfdef} that it is $G(f)$ that contains the actual video information
$$G(f) = \frac{1}{T_{\Delta}} \cdot P(f) \cdot V(f)$$
As a consequence from the Whittaker--Shannon interpolation formula that we used to construct $v(t)$, we know that $V(f)$ is band limited so that $V(f) = 0$ for all $|f| \geq \frac{1}{2 T_{\Delta}}$. This implies that $G(f)$ is also band limited to the same range (because of the multiplication). Therefore we need to have a receiver with a sampling rate of at least $\frac{1}{T_{\Delta}}$ in order to reconstruct $G(f)$. Note however that $g(t)$ contains the video signal convolved with the shape of the pixel $p(t)$. We can however assume $P(f)=1$ for $|f| \le \frac{1}{2 T_{\Delta}}$ and zero otherwise. Therefore $G(f) = V(f)$ which would imply a sinc shaped $p(t)$. This in fact is not the case since different video cards have different pixel shapes\cite{kuhn2003compromising}. However in practice, this is enough to obtain a good approximation of the signal.

\section{Reception}

\subsection{Theory}
In order to receive a copy of the video signal, we will need to apply a bandpass filter centred at a multiple of the pixel frequency. The width of the bandpass needs to be the same as the band limited video signal we want to eavesdrop. Then we need to generate an internal clock that runs at the pixel rate and use that to obtain the estimated pixel intensities. Luckily these steps are already done in a typical AM (Amplitude Modulation) receiver. Unfortunately the signal bandwidth is much wider than what a typical off-the-shelf AM receiver can handle.

However some Software Defined Radio receivers can provide the required bandwidth. The Ettus Research USRP B200 can provide more than 50 MHz of realtime bandwidth which is more than what is required to eavesdrop video signals. Software Defined Radios provide the radio samples as a quadrature vector which angle relates to the instantaneous phase in relation to the internal hardware oscillator of the hardware. The size of the vector is proportional to the received amplitude for each sample. For AM reception, we do not need the phase information since the video signal is being transmitted with a constant frequency. Therefore we can make a simple AM demodulator by taking the length of the vector of each sample. When our digital sampling rate matches the pixel rate, then each sample will contain an estimate of the pixel intensity at that time.

\subsection{Practice}
The VESA standard specifies an allowed frequency tolerance for $f_{p}$ of 0.5\%. Therefore due to hardware limitations, we might not be able to accurately tune the receiver sampling rate with enough accuracy to match the transmitted pixel rate. This means that some resampling needs to be done in software in order to create a new digital signal that matches as close as possible the transmitted pixel rate in which each sample corresponds to a pixel.

It is also true that we might be able to recover a lot of information from a signal even if our receiver is not capable of sampling the full width of the video spectrum. This means we will only receive a of $g(f)$ with a bandpass filter applied to it. In this case the digital resampling could interpolate the received samples to fit into multiple pixels. Therefore it is useful to introduce a measurement $\kappa$ of how accurate we can reconstruct pixels of $g(t)$. This measurement can be the number of input samples that have gone into constructing a single output pixels. Therefore
\begin{equation}
\kappa = receiver\_samplerate \cdot T_{\Delta} = \frac{receiver\_samplerate}{w h f_{f}}
\end{equation}
If $\kappa \geq 1$, then we can deconstruct individual pixels. If $\kappa < 1$ we are looking at a band-passed version of the signal and consecutive reconstructed pixels will depend on one another. Please refer to Figure \ref{fig:samplerates} for a visual comparison of different values of $\kappa$.

\begin{figure}[p!]
\centering
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{sr_original}
  \caption{Transmitted image}
\end{subfigure} ~
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{sr_40MHz_at_190MHz}
  \caption{$\kappa = 1.003$}
\end{subfigure} ~
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{sr_30MHz_at_190MHz}
  \caption{$\kappa = 0.753$}
\end{subfigure} ~
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{sr_20MHz_at_190MHz}
  \caption{$\kappa = 0.502$}
\end{subfigure} ~
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{sr_10MHz_at_190MHz}
  \caption{$\kappa = 0.251$}
\end{subfigure} ~
\begin{subfigure}[b]{0.45\textwidth}
  \includegraphics[width=\textwidth]{sr_5MHz_at_190MHz}
  \caption{$\kappa = 0.125$}
\end{subfigure}
\caption{The transmitted image (a) is being sent at a pixel rate of 800x600 at 60 fps with $w = 1056$, $h = 628$ and $f_{f} = 60.11$. Each of the screenshots shows the reconstructed image with the receiver (USRP B2000) running at different sample rates: (b) - 40 MHz, (c) - 30 MHz, (d) - 20 MHz, (e) - 10 MHz and (f) - 5 MHz}
\label{fig:samplerates}
\end{figure}

Another possible source of distortions is the usage of multiple wires to transmit colour information. These signals interfere with each other and the resulting pixel intensity becomes a complicated mix of the signals generated in these wires. Therefore colour information would be very difficult to obtain. Nevertheless the outlined strategy allows an eavesdropper to detect changes in colour since this would result in different signal amplitudes arriving at the receiver for each pixel.

This means that we would not be able to decode colour. Very often we can't even decode grayscale images being displayed either. This is because even grayscale pixels will depend on more than one wire to display the correct shade. What we will see is that each decoded pixel will have an intensity that relates to the colour of the original pixel in a very non-linear and non-unique fashion. Nevertheless practice shows that this is enough to read text from the remote screen as you have seen in the screenshots on Figure \ref{fig:samplerates}.

Dr Markus Kuhn has shown that the outlined procedure even works for decoding digital video signals\cite{kuhn2005electromagnetic}. If the pixel intensities are transmitted as a bit pattern rather than an analogue amplitude, the received intensity will be the average intensity in the bit pattern. The redundancy of bit patterns means that even in such case we can still receive a signal that will allow us to read text on the remote screen. 

\section{Resolution and Framerate Detection}

The outlined method for decoding the video stream relies on us having the exact values for $w$, $h$ and $f_{f}$. This is not very practical for a real world attack. We would require the adversary not to have any knowledge of the target system whatsoever. Therefore we would need to infer all of these parameters remotely by exploiting some typical characteristics of a video signal. Namely the fact that the signal is periodic.

As we have already seen, a video signal consists of video frames with width $w$ and height $h$. The speed at which such frames are transmitted is $f_{f}$. However most of the time any two consecutive frames would be identical. This would be the case if the victim is looking at static text on the screen. Therefore we can regard the transmitted signal as a repeating periodic signal of a single frame. Which means if we analyse the signal for repeating patterns we should be able to spot the repeating video frames in it and use that to estimate $f_{f}$.

\subsection{Introduction to Autocorrelation}
A good way of doing so would be calculating the discrete autocorrelation of the incoming signal which is defined as 
$$ R_{vv}(j)=\sum\limits_{i} v_{i} \bar{v}_{i-j} $$
Where $\bar{v}$ is the complex conjugate of $v$ and $j$ is the \textbf{samples lag}. In our case $v$ is the set of real samples, therefore $\bar{v} = v$. Basically the autocorrelation is a measure of the similarity of a signal with the same signal shifted by a lag. The higher the value of $R_{vv}(j)$ is, the more similar the function is at that lag. Therefore by analysing $R_{vv}(j)$, we would be able to spot any repeating patterns inside $v_{i}$.

Figure \ref{fig:autocorr} shows the discrete autocorrelation of a video signal that was captured using the Mirics USB dongle at 8 MHz (i.e. $8,000,000$ samples per second) sampling rate. The vertical axis is logarithmic, containing the decibels of the autocorrelation i.e. $10 \times log10( R_{vv} )$. The horizontal axis contains the time lag in milliseconds. This was converted from the lag in samples $j$ by $x = \frac{j}{receiver\_samplerate}$.

\begin{figure}[h]
\centering
  \includegraphics[width=0.96\textwidth]{autocorr}
  \caption{Autocorrelation of a signal}
  \label{fig:autocorr}
\end{figure}

This particular example consists of $524,288$ samples which is $65.536$ milliseconds of recording. This allows us to estimate the autocorrelation up to half of it, namely $32.768$ milliseconds. The reason is because $R_{vv}(j)=-R_{vv}(j)$ due to symmetry. We can see a peak at $16.672$ milliseconds which corresponds to a frequency of $f_{f} = \frac{1}{0.016672} = 59.98 Hz$. This is our estimate for $f_{f}$. And it makes sense, $60 Hz$ is a common refresh rate for contemporary video displays.

\subsection{Aliasing}
We should be able to see the peak repeating again at $2 \times 16.672 = 33.344 ms$. This is analogous to comparing every two consecutive frames with every two other frames. However, as this falls just outside our window it would be seen as an alias at $65.536-33.344 = 32.192 ms$. The same applies for the third peak at $3 \times 16.672 = 50.016 ms$ which would be comparing each block of three consecutive frames with the next three. This will alias at $65.536 - 50.016 = 15.52 ms$. This explains the second small peak we see on the left of the main one at $16.672 ms$ but we see that the difference in its power is already several decibels lower. Therefore any further aliasing induced would be even smaller.

It is therefore important to choose the number of samples to be used for the autocorrelation wisely in order to avoid aliasing. We need to have enough full frames in our data so that the autocorrelation can physically work. The minimum frequency we can get from an autocorrelation is $\frac{2 \times receiver\_samplerate}{numer\_of\_samples}$. It could be easily shown that the second alias is
\begin{equation}
a_{2} = \frac{1}{\frac{2}{f_{min}}-\frac{2}{f}} = \frac{1}{\frac{number\_of\_samples}{receiver\_samplerate}-\frac{2}{f}}
\end{equation}
Where $f$ is the frequency we are going to see the alias for. Therefore if we want to be able to pick up a repeating pattern of at least $f_{min} = 50 Hz$, we would need $\frac{2 \times receiver\_samplerate}{50}$ which in our case is $320,000$ samples. However having such a small number of samples if we observe a signal at 85 Hz we would discover a strong alias at $\frac{1}{\frac{320,000}{8,000,000}-\frac{2}{85} } = 60.714$ Hz which would be very misleading and will look like a legitimate signal at $60.714$ Hz. 

Let us assume $f_{lo} \leq f_{f} \leq f_{hi}$. In order to minimise aliasing, we can try to keep the second alias $a_{2}$ outside this range. Therefore we need to pick the number of samples so that
$$ \frac{1}{\frac{number\_of\_samples}{receiver\_samplerate}-\frac{2}{f_{lo}}} \leq f_{lo} \,\,\,\,\ or \,\,\,\,\ \frac{1}{\frac{number\_of\_samples}{receiver\_samplerate}-\frac{2}{f_{hi}}} \geq f_{hi} $$
Which means that
$$ 3 \times \frac{receiver\_samplerate}{f_{lo}} \leq number\_of\_samples $$
or
$$3 \times \frac{receiver\_samplerate}{f_{hi}} \geq number\_of\_samples $$
and don't forget that in the same time we have the condition
$$\frac{2 \times receiver\_samplerate}{f_{lo}} \leq numer\_of\_samples$$
so in the end, in order to eliminate the second alias in the desired region from $f_{lo}$ to $f_{hi}$ in the autocorrelation, we would need to choose the number of samples to be
\begin{equation}
\label{eq:autocorraliasingcondition}
numer\_of\_samples \geq 3 \times \frac{receiver\_samplerate}{f_{lo}}
\end{equation}
To paraphrase this result, we will need to do the autocorrelation on at least 3 frames worth of samples for the lowest frequency in our range $f_{lo}$ to avoid second order aliasing interfering with our plot.

\subsection{Number of Lines in a Frame}

We were able to estimate $f_{f}$ using an autocorrelation and eliminate aliased signals in the frequency window that we are looking to detect repetitions. However, we still have not estimated neither $w$, nor $h$. As a matter of fact we might not be able to measure $w$ at all. The reason is that $w$ might be a continuous signal and could potentially contain any number of pixels. However, each line of $w$ pixels repeat $h$ times in a frame. There are, however, the blanking intervals that repeat on each line. Therefore we can use their repeating nature to estimate $h$ from the autocorrelation plot.

For this reason we need to zoom in to our plot. Refer to Figure \ref{fig:autocorr_zoomed} which is a zoomed out version of the figure we saw in the previous subsection. If we still have our allowed $f_{f}$ window between $f_{lo}$ and $f_{hi}$, then we can assume that $h$ also spans between $h_{lo}$ and $h_{hi}$. We would therefore expect to see a peak between $\frac{1}{f_{hi} \cdot h_{hi}}$ and $\frac{1}{f_{lo} \cdot h_{lo}}$ milliseconds. If we detect a peak at time $t_{peak}$, then this would correspond to $h = round \left( \frac{1}{t_{peak} \cdot f_{f}} \right)$. Note that we should have already estimated $f_{f}$.

\begin{figure}[h]
\centering
  \includegraphics[width=0.96\textwidth]{autocorr_zoomed}
  \caption{Zoomed in version of \ref{fig:autocorr}}
  \label{fig:autocorr_zoomed}
\end{figure}

Our plot shows a peak at $0.017875$ milliseconds. Since we already estimated $f_{f} = 59.98 Hz$, then $h = \| \frac{1000}{0.017875 \times 59.98} \| = 933$ lines. If we look at a list of VESA video modes, we can see that there is a conveniently close video mode that corresponds to $h = 933$ and $f_{f} = 59.98$. It is the ``1440x900 @ 60 Hz'' video mode with $w = 1904$ pixels, $h = 932$ lines and $f_{f}=60 Hz$. Therefore we could use the value of $w = 1904$ for our estimate of the number of pixels in a row. This will keep the aspect ratio correct.

We should not worry about aliasing since the number of samples in the autocorrelation is much bigger than our range. We can see on the plot the autocorrelation values repeating for each two lines, each three lines, etc. This results in a number of peaks repeating with the rate at which individual lines repeat in the video signal.

\subsection{Errors}

There is a limit on how accurately one can determine $f_{f}$ and $h$ using the outlined autocorrelation method. This depends on the sampling rate of the device. The resolution of the autocorrelation is $\delta f = \frac{1}{receiver\_samplerate}$. Therefore we can only say that if there is a peak at $t_{x}$ in the autocorrelation, then we have a repeating component in the signal with a frequency $f_{x} \pm \delta f$.

The accuracy at which we can determine $h$ depends both on the accuracy of $f_{f}$ and $t_{peak}$ and can vary. Furthermore $h$ should be rounded to an integer (we can only display an integer number of lines on a PC screen) which introduces further errors. Our definition for $h$ is
$$h = \| \frac{1}{t_{peak} \cdot f_{f}} \| \pm (\delta h + 0.5)$$
Where $0.5$ comes from the rounding. Also the uncertainties in $t_{peak}$ and $f_{f}$ are $\delta f$ since both are being read from the same autocorrelation plot in milliseconds. In order to do error propagation, we need to take the partial derivatives with respect to $f_{f}$ and $t_{peak}$.
$$\frac{\partial h}{\partial f_{f}} = - \frac{1}{t_{peak} \cdot f_{f}^2}
 \,\,\,\,\ and \,\,\,\,\ \
\frac{\partial h}{\partial t_{peak}} = - \frac{1}{f_{f} \cdot t_{peak}^2}$$
So for the uncertainty in $h$, we have
$$\delta h =
\sqrt{\left( \frac{\partial h}{\partial f_{f}} \delta f_{f} \right)^2 + \left( \frac{\partial h}{\partial t_{peak}} \delta t_{peak} \right)^2} = 
\sqrt{\frac{1}{f_{f}^2} + \frac{1}{t_{peak}^2}} \times \frac{\delta f}{f_{f} \cdot t_{peak}}$$
We can also observe that the larger the sample rate gets, the smaller $\delta f$ and $\delta t$ get.

\chapter{Practical attack} 

Before explaining how the software works internally, let's present a demonstration of a practical video eavesdropping attack. Its main aim is to show the ease with which such an attack could happen. In the meantime this will give an opportunity to explain the characteristics of the received signal and how they are exploited.

As in the real world, we will start with no knowledge of the victim's system. We will estimate the frequency at which the emission strength has the best Signal to Noise Ratio (SNR). We will then analyse the signal to detect the resolution and refresh rate of the screen. We will afterwards lock onto the signal and try to recover the original video. We will also discuss some techniques that could be utilized to improve the quality of the image.

\section{The Setup}

The choice for a SDR front-end for this demonstration is a USRP B200\footnote{Refer to \ref{sec:hw} Hardware for discussion on currently available SDR devices.}. Depending on the particular requirements, an attacker might prefer mobility over accuracy and choose the smaller Mirics FlexiTV\texttrademark MSi3101 SDR USB Dongle. However, for this demonstration we will attempt to obtain the highest possible resolution. Therefore we need an SDR radio that is capable of obtaining a wide bandwidth. This makes the 32 MHz of Bandwidth that the USRP provides a much better choice than the 8 MHz available from the Mirics dongle.

[Antenna]

[Location of victim]

[Victim's fonts]

\section{Preparation}

\chapter{Implementation} 

\section{Hardware}
\label{sec:hw} 

\begin{figure}[h!]
 
  \centering
    \includegraphics[width=0.9\textwidth]{equipment}
    \caption{From left to right: MSi3101, AverMedia antenna and USRP B200}
\end{figure}


\section{Architecture}

\subsection{Main Library}

\subsection{JavaGUI}

\subsubsection{Multiplatform}

\subsubsection{Graphical Interface}

\subsubsection{Visualisation}

\section{Digital Signal Processing}

\subsection{Overview}

\subsection{Signal Reconstruction}

\subsubsection{Multithreading}

\subsubsection{Demodulation}

\subsubsection{Re-sampling}

\subsubsection{Auto Gain}

\subsubsection{Low-pass}

\subsection{Frame Synchronization}

\subsection{Resolution Detection}

\subsection{Extended Bandwidth}

\subsection{Testing and Benchmarking}

\chapter{Summary and Conclusions} 

[Summarize results]

[potential future work]

\appendix
\singlespacing

\bibliographystyle{unsrt} 
\bibliography{dissertation} 

\end{document}
